{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions:\n",
    "- connect_2_api() \n",
    "- refresh_token()\n",
    "- save_to_folder(dataframe, 'specific_path_and_name_string', 'separator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3 Updates / changes\n",
    "\n",
    "- 1.  Pulling most of the extraneous data out of the Python data request loop (now feeding it the list of SP500)\n",
    "- 2. Will explore saving company data in dictionary format vs in pandas datframe at first (column / pivoting issue with the financial data)\n",
    "- 3. Will open and explore my UFL data to align on the basic dataset I will run my first models with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login and Refresh\n",
    "- note: avoid turning connecting to api into a function as it is difficult to change variables needed for any api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import getpass\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload set\n",
      "json gathtered\n",
      "\n",
      "\n",
      "Your access token expires in 60 minutes. After it expires, run the cell immediately below this one to generate a new token and continue to use the query cell. \n",
      "\n",
      "For now, skip ahead to the section 'Make a Query'.\n"
     ]
    }
   ],
   "source": [
    "# Definining my email, pw, client id and secret here so I can use it here and in API pull cell below  \n",
    "email = 'xxxxxxxx@xxxxx.com'\n",
    "password = 'XXXYYY'\n",
    "client_id = 'XXXXXXXXXXXXXXXXX'\n",
    "client_secret = 'XXXXXXXXXXXXXXXXX'\n",
    "\n",
    "    #def connect_2_api():  #Now I can just login in a cell using connect_2_api()\n",
    "body_auth = {'username' : email,\n",
    "            'client_id': client_id,\n",
    "            'client_secret' : client_secret,\n",
    "            'password' : password,\n",
    "            'grant_type' : 'password',\n",
    "            'platform' : 'ipynb' }\n",
    "\n",
    "payload = urlencode(body_auth)\n",
    "url = 'https://api.xbrl.us/oauth2/token'\n",
    "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "print(\"payload set\")\n",
    "res = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "auth_json = res.json()\n",
    "print('json gathtered')\n",
    "if 'error' in auth_json:\n",
    "    print (\"\\n\\nThere was a problem generating an access token with these credentials. Run the first cell again to enter credentials.\")\n",
    "else:\n",
    "    print (\"\\n\\nYour access token expires in 60 minutes. After it expires, run the cell immediately below this one to generate a new token and continue to use the query cell. \\n\\nFor now, skip ahead to the section 'Make a Query'.\")\n",
    "access_token = auth_json['access_token']\n",
    "refresh_token = auth_json['refresh_token']\n",
    "newaccess = ''\n",
    "newrefresh = ''\n",
    "    #print('access token: ' + access_token + ' refresh token: ' + refresh_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your access token is refreshed for 60 minutes. If it expires again, run this cell to generate a new token and continue to use the query cells below.\n",
      "69ace430-f0cf-4148-ba6a-0f49ebc80572\n"
     ]
    }
   ],
   "source": [
    "#def refresh_token(): # call refresh_token() if you need to refresh\n",
    "token = token if newrefresh != '' else refresh_token\n",
    "\n",
    "refresh_auth = {'client_id': ''.join(client_id), # pulling from api connect cell\n",
    "            'client_secret' : ''.join(client_secret), # pulling from api connect cell\n",
    "            'grant_type' : 'refresh_token',\n",
    "            'platform' : 'ipynb',\n",
    "            'refresh_token' : ''.join(token) }\n",
    "refreshres = requests.post(url, data=refresh_auth)\n",
    "refresh_json = refreshres.json()\n",
    "access_token = refresh_json['access_token']\n",
    "refresh_token = refresh_json['refresh_token']\n",
    "#print('access token: ' + access_token + 'refresh token: ' + refresh_token)\n",
    "print('Your access token is refreshed for 60 minutes. If it expires again, run this cell to generate a new token and continue to use the query cells below.')\n",
    "print(access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined my SP500_CIK_List here\n",
    "Added to API query in the params variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Wiki_SP500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies') #returns multiple tables ours happens to be [0]\n",
    "SP500_CIK_Array = Wiki_SP500[0]['CIK']\n",
    "SP500_CIK_List = list('{:010d}'.format(n) for n in SP500_CIK_Array.values)  # Using list comprehension to return CIK codes with all leading zeroes\n",
    "\n",
    "# I now have a pd daframe of the Wikipedia table\n",
    "\n",
    "# SP500_CIK_List is a list datatype holding all 500 CIK Codes I need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined what financial items I want returned\n",
    "Added to API query in params variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get my designated elements list                                         \n",
    "GAAP_Elements = ['Revenues',                                       # Sales\n",
    "                 'NetCashProvidedByUsedInOperatingActivities',     # EBITDA\n",
    "                 'Assets',                                         # Assets\n",
    "                 'Liabilities'                                     # Liabilties\n",
    "                ]\n",
    "# Note: I said I'd also pull Expenses, EBIT/DA, Accounts Receivable, D&A -- some flaws discussed in paper notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pull:\n",
    "- Pull past years worth of financial info\n",
    "- Write script to loop through each dict, and consolidate them into a combined dict, then combine all dicts\n",
    "- Have the ability to call out whether I have missing information (achieving this by devault None values, will remove any cases where I don't have everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset_value = 0\n",
    "res_df = []\n",
    "\n",
    "sic_code = [2080] ### v1 - OFF in API Call below\n",
    "\n",
    "periods = ['Y']\n",
    "\n",
    "years = [2022]  #,   # v1 - only doing 2022 and 202 while constructing... likely will variable-ize this \n",
    "         #2021,\n",
    "         #2020]   # , <- put comma back\n",
    "         #2019,   \n",
    "         #2018,\n",
    "         #2017\n",
    "        # put bracket back!\n",
    "\n",
    "string_sic = [str(int) for int in sic_code] # OFF in API URI\n",
    "string_years = [str(int) for int in years]\n",
    "\n",
    "fields = [ # this is the list of the characteristics of the data being returned by the query [COLUMNS]\n",
    "         'period.fiscal-year.sort(DESC)',\n",
    "         'entity.name.sort(ASC)',\n",
    "         'concept.local-name.sort(ASC)', # MARK - going to try and modify this from 'local-name' TO 'is-base'\n",
    "         'fact.value',\n",
    "         'unit',\n",
    "         'fact.decimals',\n",
    "         'report.filing-date',\n",
    "         'report.sic-code',             # [OFF in API URI] - \n",
    "         'entity.cik' \n",
    "        ]\n",
    "\n",
    "params = { \n",
    "         'concept.local-name': ','.join(GAAP_Elements),                  # MARK - modified this to use my specified list of FStmt Items\n",
    "         #'report.sic-code': ','.join(string_sic),                       # OFF -- spy companies\n",
    "         'entity.cik': ','.join(SP500_CIK_List),                         # ON -- set to list of SP500\n",
    "         'period.fiscal-year': ','.join(string_years),                   # ON -- Set to 2022 only | MARK - turn on to limit the num of yrs (currently will provide all available)\n",
    "         'period.fiscal-period': ','.join(periods),\n",
    "         'fact.ultimus': 'TRUE', # return only the latest occurrence of a specific fact (eg. 2018 revenues)\n",
    "         'fact.has-dimensions': 'FALSE', # generally, 'FALSE' will return face financial data only\n",
    "         'fields': ','.join(fields)\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed Nov  8 00:52:33 2023 markstansky@gmail.com (client ID: 6a5b399f ...) started the query and\n",
      "up to 500 records are found so far ...\n",
      "up to 1000 records are found so far ...\n",
      "up to 1500 records are found so far ...\n",
      "up to 2000 records are found so far ...\n",
      "\n",
      "This Basic Individual Member account has a limit of  2000  rows per query from our Public Filings Database. If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\n",
      "\n",
      "\n",
      "At Wed Nov  8 00:57:03 2023, the query finished with   2000   rows returned in 0:04:29.782239 for \n",
      "https://api.xbrl.us/api/v1/fact/search?concept.local-name=Revenues,NetCashProvidedByUsedInOperatingActivities,Assets,Liabilities&entity.cik=0000066740,0000091142,0000001800,0001551152,0001467373,0000007084,0000796343,0000008670,0000874761,0000004977,0001090872,0001559720,0000002969,0001086222,0000766421,0000915913,0001035443,0001097149,0001579241,0000352541,0000899051,0001652044,0001652044,0000764180,0001018724,0001748790,0000002488,0001002910,0000006201,0000004904,0000004962,0000005272,0001053507,0001410636,0000820027,0001037868,0000318154,0000820313,0000006281,0001013462,0000315293,0001841666,0000320193,0000006951,0001521332,0000947484,0001596532,0000354190,0001267238,0000732717,0000731802,0000769397,0000866787,0000915912,0000008818,0001069183,0001701605,0000009389,0000070858,0000701985,0000010456,0000010795,0000011544,0001067983,0000764478,0000012208,0000842023,0000875045,0001364742,0001393818,0001390777,0000012927,0001075531,0000908255,0001037540,0000885725,0000014272,0001730168,0001383312,0000079282,0000014693,0001144519,0001043277,0000813672,0001590895,0000906345,0000016732,0000927628,0000721371,0001170010,0000815097,0001783180,0001596783,0000018230,0001374310,0001138118,0001402057,0001306830,0001140859,0001071739,0001130310,0001725057,0001324404,0001100682,0000316709,0001091667,0000093410,0001058090,0000896159,0000313927,0001739940,0000020286,0000723254,0000858877,0000831001,0000759944,0000021076,0001156375,0000811156,0000021344,0001058290,0000021665,0001166691,0000028412,0000023217,0001163165,0001047862,0000016918,0001868275,0000711404,0000900075,0000024741,0001755672,0001057352,0000909832,0000858470,0001051470,0000277948,0000026172,0000064803,0000882184,0000313616,0000940944,0000927066,0000315189,0000027904,0000818479,0001090012,0001093557,0001539838,0001297996,0001393612,0001744489,0000029534,0000935703,0000715957,0001286681,0000029905,0001751788,0000936340,0001326160,0001666700,0000915389,0001551182,0001065088,0000031462,0000827052,0001099800,0000712515,0001156039,0000059478,0000032604,0001463101,0000065984,0000821189,0001352010,0000033213,0000033185,0001101239,0000906107,0000920522,0001001250,0001370637,0001095073,0001711269,0000072741,0001109357,0001324424,0000746515,0001289490,0000034088,0001048695,0001013237,0000814547,0000815556,0000034903,0001048911,0000035527,0001274494,0001031296,0001136893,0000798354,0001175454,0000037785,0000037996,0001262039,0001659166,0001754301,0001754301,0000038777,0000831259,0001121788,0000749251,0001932393,0000849399,0001474735,0000040533,0000040545,0000040704,0001467858,0000040987,0000882095,0000320335,0001123360,0000886982,0000045012,0000874766,0000046080,0000860730,0000765880,0001000228,0000047111,0000004447,0001645590,0001585689,0000859737,0000354950,0000773840,0000048465,0001070750,0000004281,0000047217,0000048898,0000049071,0000049196,0001501585,0000051143,0000832101,0000874716,0000049826,0001110803,0000879169,0001699150,0001145197,0000050863,0001571949,0000051253,0000051434,0000051644,0000896878,0001035267,0000914208,0001687229,0001478242,0001020569,0000728535,0000779152,0000052988,0000200406,0000833444,0000019617,0001043604,0000055067,0001944048,0001418135,0000091576,0001601046,0000055785,0000879101,0001506307,0000319201,0001637459,0000056873,0000202058,0000920148,0000707549,0001679273,0001300514,0001336920,0000920760,0001707925,0001335258,0001065696,0000936468,0000060086,0000060667,0001397187,0001489393,0000036270,0000101778,0001510295,0001278021,0001048286,0000062709,0000916076,0000062996,0001141391,0000891103,0000063754,0000063908,0000927653,0001613103,0000310158,0001326801,0001099219,0001037646,0000789570,0000827054,0000723125,0000789019,0000912595,0001682852,0000851968,0001179929,0000024545,0001103982,0001280452,0000865752,0001059556,0000895421,0001285785,0000068505,0001408198,0001120193,0001002047,0001065280,0001164727,0001564708,0001564708,0000753308,0000320187,0001111711,0000072331,0000702165,0000073124,0001133421,0001513761,0001013871,0000073309,0001045810,0000906163,0001413447,0000898173,0000797468,0000878927,0000029989,0001097864,0001039684,0001341439,0001781335,0000075362,0000075677,0001327567,0000813828,0000076334,0000723531,0001590955,0001633917,0000077360,0000077476,0000078003,0001004980,0001413329,0001534701,0000764622,0001038357,0000713676,0000945841,0000079879,0000922224,0001126328,0000080424,0000080661,0001045609,0001137774,0000788784,0000857005,0001393311,0000822416,0001604778,0001050915,0000804328,0001022079,0001037038,0000720005,0000101829,0000726728,0000910606,0000872589,0001281761,0001060391,0000943819,0000031791,0000315213,0001024478,0000084839,0000882835,0000745732,0000884887,0000064040,0001108524,0001034054,0000087347,0001137789,0001012100,0001032208,0001373715,0000089800,0001063761,0000004127,0000091419,0000091440,0001419612,0000092122,0000092380,0000093556,0000829224,0000093751,0001022671,0001757898,0000310764,0001601712,0000883241,0000096021,0001283699,0001113169,0000946581,0001116132,0001389170,0000027419,0001385157,0001094285,0000096943,0000097210,0001318605,0000097476,0000217346,0000097745,0000109198,0000916365,0001466258,0001260221,0000086312,0000864749,0000092230,0000860731,0000100493,0000036104,0000074208,0001403568,0000100885,0000100517,0001090727,0001067701,0000731766,0000352915,0001035002,0000740260,0001967680,0001014473,0001442145,0000732712,0000875320,0000103379,0001792044,0001705696,0001403161,0001396009,0000943452,0001618921,0000104169,0001437107,0000823768,0001000697,0000783325,0000072971,0000766704,0000105770,0000106040,0001732845,0000106535,0000106640,0000107263,0001140536,0000277135,0001174922,0000072903,0001524472,0001041061,0000877212,0001136869,0000109380,0001555280&period.fiscal-year=2022&period.fiscal-period=Y&fact.ultimus=TRUE&fact.has-dimensions=FALSE&fields=period.fiscal-year.sort(DESC),entity.name.sort(ASC),concept.local-name.sort(ASC),fact.value,unit,fact.decimals,report.filing-date,report.sic-code,entity.cik,fact.offset(1500)\n"
     ]
    }
   ],
   "source": [
    "# This consolidates the fields defined above, and pulls API data via a loop:\n",
    "\n",
    "search_endpoint = 'https://api.xbrl.us/api/v1/fact/search' #looking for facts (Not reports, filers, etc.)\n",
    "orig_fields = params['fields']\n",
    "\n",
    "\n",
    "# Begin Loop ----------------------\n",
    "count = 0\n",
    "query_start = datetime.now()\n",
    "printed = False\n",
    "while True:\n",
    "    if not printed:\n",
    "        print(\"On\", query_start.strftime(\"%c\"), email, \"(client ID:\", str(client_id.split('-')[0]), \"...) started the query and\")  #client id defined in api connect cell\n",
    "        printed = True\n",
    "    res = requests.get(search_endpoint, params=params, headers={'Authorization' : 'Bearer {}'.format(access_token)}) # first GET request\n",
    "    res_json = res.json()\n",
    "    if 'error' in res_json:\n",
    "        print('There was an error: {}'.format(res_json['error_description']))\n",
    "        break\n",
    "\n",
    "    print(\"up to\", str(offset_value + res_json['paging']['limit']), \"records are found so far ...\")\n",
    "\n",
    "    res_df += res_json['data']\n",
    "\n",
    "    if res_json['paging']['count'] < res_json['paging']['limit']: #here it's checking for whether there's more to page & printing an update\n",
    "        print(\" - this set contained fewer than the\", res_json['paging']['limit'], \"possible, only\", str(res_json['paging']['count']), \"records.\")\n",
    "        break \n",
    "    else:\n",
    "        offset_value += res_json['paging']['limit'] # increments offset_value\n",
    "        if 100 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 10 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        elif 500 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 4 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "\n",
    "if not 'error' in res_json:\n",
    "    current_datetime = datetime.now().replace(microsecond=0)\n",
    "    time_taken = current_datetime - query_start\n",
    "    index = pd.DataFrame(res_df).index\n",
    "    total_rows = len(index)\n",
    "    your_limit = res_json['paging']['limit']\n",
    "    limit_message = \"If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\\n\"\n",
    "\n",
    "    if your_limit == 100:\n",
    "        print(\"\\nThis non-Member account has a limit of \" , 10 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "    elif your_limit == 500:\n",
    "        print(\"\\nThis Basic Individual Member account has a limit of \", 4 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "\n",
    "    print(\"\\nAt \" + current_datetime.strftime(\"%c\") +  \", the query finished with  \", str(total_rows), \"  rows returned in \" + str(time_taken) + \" for \\n\" +  urllib.parse.unquote(res.url))\n",
    "\n",
    "\n",
    "# OFF -- Dataframe creation -- (turns res_df, a list of dictionaries returned from API, and presents as a dataframe)\n",
    "\n",
    "#    df = pd.DataFrame(res_df)\n",
    "#    # the format truncates the HTML display of numerical values to two decimals; .csv data is unaffected\n",
    "#    pd.options.display.float_format = '{:,.2f}'.format\n",
    "#    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining my 'Factory function'\n",
    "- Creating a wireframe of the dictionary I eventually want to insert into pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step needs to create ~500 dictionaries to hold all SP500 company's repsective data\n",
    "- Also need a unique identifier to keep track of each dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold all my companies\n",
    "all_company_financials_list_empty = []\n",
    "\n",
    "\n",
    "for company in SP500_CIK_List:\n",
    "    # STEP 1: create a label-list for yearxdata \n",
    "    temp_lineitem_list = []\n",
    "    for year in years: #1 year\n",
    "        for item in GAAP_Elements: #4 elements\n",
    "            temp_lineitem_list.append(f'FY{year}_{item}') # adds year_x_data term to lineitem list\n",
    "        # STEP 2: turn company yearxdata fields into a blank dictionary that holds None / NAs\n",
    "        company_dictionary = {x:None for x in temp_lineitem_list}\n",
    "    # STEP 3: Add Company Name and Append completed dictionary to master list\n",
    "    company_dictionary['CIK_number'] = str(company) #append a unique identifier to the dictionary    \n",
    "    all_company_financials_list_empty.append(company_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Blank Factory Dict\n",
    "- Lookup / Select Factory on CIK code\n",
    "- Update finanicals where there is a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create 'searcher' for loop to get index of dict with matching CIK code\n",
    "for dictionary in res_df: # loops same number of times as I have json dicts\n",
    "    for financial_dict in all_company_financials_list_empty: # now we iterate through each dictionary we have\n",
    "        if financial_dict['CIK_number'] == dictionary['entity.cik']:\n",
    "            \n",
    "            # update corresponding dictionary\n",
    "            \n",
    "            # first create temp variables\n",
    "            temp_yr = dictionary['period.fiscal-year']\n",
    "            temp_lclname = dictionary['concept.local-name']\n",
    "            \n",
    "            # then update matching line items\n",
    "            if f'FY{temp_yr}_{temp_lclname}' in financial_dict: # searches current financial_dict for matching financial line item\n",
    "                financial_dict[f'FY{temp_yr}_{temp_lclname}'] = dictionary['fact.value']\n",
    "                \n",
    "            else: \n",
    "                missing_vals.append(f'FY{temp_yr}_{temp_lclname}') # TO UPDATE: create and keep a list of missing values\n",
    "            #Before exiting loop, add additional data from json dict\n",
    "                ## Note: this code is inefficient -- will reassign the entity name, sic-code, filing each time a\n",
    "                ## this loop is entered (when SP500's CIK list finds a match in API's entity CIK)\n",
    "            # list of keys I want to append onto my custom dictionary\n",
    "            extra_info = ['entity.name','report.sic-code','report.filing-date']\n",
    "\n",
    "            for info in extra_info:\n",
    "                financial_dict[info] = dictionary[info] # Adds extra api metadata that will useful for my analysis\n",
    "        else: pass\n",
    "\n",
    "\n",
    "# first dict will have CIK code -- use that to ID the dictionary needed\n",
    "\n",
    "# Then go into lower loop to correclty slot datapoint into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throw my new-fangled data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FY2022_Revenues</th>\n",
       "      <th>FY2022_NetCashProvidedByUsedInOperatingActivities</th>\n",
       "      <th>FY2022_Assets</th>\n",
       "      <th>FY2022_Liabilities</th>\n",
       "      <th>CIK_number</th>\n",
       "      <th>entity.name</th>\n",
       "      <th>report.sic-code</th>\n",
       "      <th>report.filing-date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.422900e+10</td>\n",
       "      <td>5.591000e+09</td>\n",
       "      <td>4.645500e+10</td>\n",
       "      <td>3.168500e+10</td>\n",
       "      <td>0000066740</td>\n",
       "      <td>3M COMPANY</td>\n",
       "      <td>3841.0</td>\n",
       "      <td>2023-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.914000e+08</td>\n",
       "      <td>3.332300e+09</td>\n",
       "      <td>1.584600e+09</td>\n",
       "      <td>0000091142</td>\n",
       "      <td>A. O. Smith Corporation</td>\n",
       "      <td>3630.0</td>\n",
       "      <td>2023-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.365300e+10</td>\n",
       "      <td>9.581000e+09</td>\n",
       "      <td>7.443800e+10</td>\n",
       "      <td>3.001100e+10</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.805400e+10</td>\n",
       "      <td>2.494300e+10</td>\n",
       "      <td>1.388050e+11</td>\n",
       "      <td>1.215180e+11</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>2023-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.159430e+10</td>\n",
       "      <td>9.541129e+09</td>\n",
       "      <td>4.726339e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001467373</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>7389.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0000877212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FY2022_Revenues  FY2022_NetCashProvidedByUsedInOperatingActivities  \\\n",
       "0       3.422900e+10                                       5.591000e+09   \n",
       "1                NaN                                       3.914000e+08   \n",
       "2       4.365300e+10                                       9.581000e+09   \n",
       "3       5.805400e+10                                       2.494300e+10   \n",
       "4       6.159430e+10                                       9.541129e+09   \n",
       "..               ...                                                ...   \n",
       "498              NaN                                                NaN   \n",
       "499              NaN                                                NaN   \n",
       "500              NaN                                                NaN   \n",
       "501              NaN                                                NaN   \n",
       "502              NaN                                                NaN   \n",
       "\n",
       "     FY2022_Assets  FY2022_Liabilities  CIK_number              entity.name  \\\n",
       "0     4.645500e+10        3.168500e+10  0000066740               3M COMPANY   \n",
       "1     3.332300e+09        1.584600e+09  0000091142  A. O. Smith Corporation   \n",
       "2     7.443800e+10        3.001100e+10  0000001800      ABBOTT LABORATORIES   \n",
       "3     1.388050e+11        1.215180e+11  0001551152              AbbVie Inc.   \n",
       "4     4.726339e+10                 NaN  0001467373            Accenture plc   \n",
       "..             ...                 ...         ...                      ...   \n",
       "498            NaN                 NaN  0001041061                      NaN   \n",
       "499            NaN                 NaN  0000877212                      NaN   \n",
       "500            NaN                 NaN  0001136869                      NaN   \n",
       "501            NaN                 NaN  0000109380                      NaN   \n",
       "502            NaN                 NaN  0001555280                      NaN   \n",
       "\n",
       "     report.sic-code report.filing-date  \n",
       "0             3841.0         2023-02-08  \n",
       "1             3630.0         2023-02-14  \n",
       "2             2834.0         2023-11-01  \n",
       "3             2834.0         2023-02-17  \n",
       "4             7389.0         2023-10-12  \n",
       "..               ...                ...  \n",
       "498              NaN                NaN  \n",
       "499              NaN                NaN  \n",
       "500              NaN                NaN  \n",
       "501              NaN                NaN  \n",
       "502              NaN                NaN  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_df = pd.DataFrame(all_company_financials_list_empty) \n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   FY2022_Revenues                                    259 non-null    float64\n",
      " 1   FY2022_NetCashProvidedByUsedInOperatingActivities  394 non-null    float64\n",
      " 2   FY2022_Assets                                      406 non-null    float64\n",
      " 3   FY2022_Liabilities                                 378 non-null    float64\n",
      " 4   CIK_number                                         503 non-null    object \n",
      " 5   entity.name                                        407 non-null    object \n",
      " 6   report.sic-code                                    407 non-null    float64\n",
      " 7   report.filing-date                                 407 non-null    object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 31.6+ KB\n"
     ]
    }
   ],
   "source": [
    "SP500_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Try 2: Splitting SP500 List into two\n",
    "- Hopefully each time I call the API I can update the master dictionary and sequentially append each to my dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SP500_CIK_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPY1 = SP500_CIK_List[:250]\n",
    "SPY2 = SP500_CIK_List[250:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Pull 1/2 - SPY1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset_value = 0\n",
    "res_df = []\n",
    "\n",
    "sic_code = [2080] ### v1 - OFF in API Call below\n",
    "\n",
    "periods = ['Y']\n",
    "\n",
    "years = [2022]  #,   # v1 - only doing 2022 and 202 while constructing... likely will variable-ize this \n",
    "         #2021,\n",
    "         #2020]   # , <- put comma back\n",
    "         #2019,   \n",
    "         #2018,\n",
    "         #2017\n",
    "        # put bracket back!\n",
    "\n",
    "string_sic = [str(int) for int in sic_code] # OFF in API URI\n",
    "string_years = [str(int) for int in years]\n",
    "\n",
    "fields = [ # this is the list of the characteristics of the data being returned by the query [COLUMNS]\n",
    "         'period.fiscal-year.sort(DESC)',\n",
    "         'entity.name.sort(ASC)',\n",
    "         'concept.local-name.sort(ASC)', # MARK - going to try and modify this from 'local-name' TO 'is-base'\n",
    "         'fact.value',\n",
    "         'unit',\n",
    "         'fact.decimals',\n",
    "         'report.filing-date',\n",
    "         'report.sic-code',             # [OFF in API URI] - \n",
    "         'entity.cik' \n",
    "        ]\n",
    "\n",
    "params = { \n",
    "         'concept.local-name': ','.join(GAAP_Elements),                  # MARK - modified this to use my specified list of FStmt Items\n",
    "         #'report.sic-code': ','.join(string_sic),                       # OFF -- spy companies\n",
    "         'entity.cik': ','.join(SPY1),                         # ON -- set to list of SP500\n",
    "         'period.fiscal-year': ','.join(string_years),                   # ON -- Set to 2022 only | MARK - turn on to limit the num of yrs (currently will provide all available)\n",
    "         'period.fiscal-period': ','.join(periods),\n",
    "         'fact.ultimus': 'TRUE', # return only the latest occurrence of a specific fact (eg. 2018 revenues)\n",
    "         'fact.has-dimensions': 'FALSE', # generally, 'FALSE' will return face financial data only\n",
    "         'fields': ','.join(fields)\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed Nov  8 01:04:05 2023 markstansky@gmail.com (client ID: 6a5b399f ...) started the query and\n",
      "up to 500 records are found so far ...\n",
      "up to 1000 records are found so far ...\n",
      "up to 1500 records are found so far ...\n",
      " - this set contained fewer than the 500 possible, only 213 records.\n",
      "\n",
      "This Basic Individual Member account has a limit of  2000  rows per query from our Public Filings Database. If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\n",
      "\n",
      "\n",
      "At Wed Nov  8 01:06:45 2023, the query finished with   1213   rows returned in 0:02:39.826287 for \n",
      "https://api.xbrl.us/api/v1/fact/search?concept.local-name=Revenues,NetCashProvidedByUsedInOperatingActivities,Assets,Liabilities&entity.cik=0000066740,0000091142,0000001800,0001551152,0001467373,0000007084,0000796343,0000008670,0000874761,0000004977,0001090872,0001559720,0000002969,0001086222,0000766421,0000915913,0001035443,0001097149,0001579241,0000352541,0000899051,0001652044,0001652044,0000764180,0001018724,0001748790,0000002488,0001002910,0000006201,0000004904,0000004962,0000005272,0001053507,0001410636,0000820027,0001037868,0000318154,0000820313,0000006281,0001013462,0000315293,0001841666,0000320193,0000006951,0001521332,0000947484,0001596532,0000354190,0001267238,0000732717,0000731802,0000769397,0000866787,0000915912,0000008818,0001069183,0001701605,0000009389,0000070858,0000701985,0000010456,0000010795,0000011544,0001067983,0000764478,0000012208,0000842023,0000875045,0001364742,0001393818,0001390777,0000012927,0001075531,0000908255,0001037540,0000885725,0000014272,0001730168,0001383312,0000079282,0000014693,0001144519,0001043277,0000813672,0001590895,0000906345,0000016732,0000927628,0000721371,0001170010,0000815097,0001783180,0001596783,0000018230,0001374310,0001138118,0001402057,0001306830,0001140859,0001071739,0001130310,0001725057,0001324404,0001100682,0000316709,0001091667,0000093410,0001058090,0000896159,0000313927,0001739940,0000020286,0000723254,0000858877,0000831001,0000759944,0000021076,0001156375,0000811156,0000021344,0001058290,0000021665,0001166691,0000028412,0000023217,0001163165,0001047862,0000016918,0001868275,0000711404,0000900075,0000024741,0001755672,0001057352,0000909832,0000858470,0001051470,0000277948,0000026172,0000064803,0000882184,0000313616,0000940944,0000927066,0000315189,0000027904,0000818479,0001090012,0001093557,0001539838,0001297996,0001393612,0001744489,0000029534,0000935703,0000715957,0001286681,0000029905,0001751788,0000936340,0001326160,0001666700,0000915389,0001551182,0001065088,0000031462,0000827052,0001099800,0000712515,0001156039,0000059478,0000032604,0001463101,0000065984,0000821189,0001352010,0000033213,0000033185,0001101239,0000906107,0000920522,0001001250,0001370637,0001095073,0001711269,0000072741,0001109357,0001324424,0000746515,0001289490,0000034088,0001048695,0001013237,0000814547,0000815556,0000034903,0001048911,0000035527,0001274494,0001031296,0001136893,0000798354,0001175454,0000037785,0000037996,0001262039,0001659166,0001754301,0001754301,0000038777,0000831259,0001121788,0000749251,0001932393,0000849399,0001474735,0000040533,0000040545,0000040704,0001467858,0000040987,0000882095,0000320335,0001123360,0000886982,0000045012,0000874766,0000046080,0000860730,0000765880,0001000228,0000047111,0000004447,0001645590,0001585689,0000859737,0000354950,0000773840,0000048465,0001070750,0000004281,0000047217,0000048898,0000049071,0000049196,0001501585,0000051143,0000832101,0000874716,0000049826&period.fiscal-year=2022&period.fiscal-period=Y&fact.ultimus=TRUE&fact.has-dimensions=FALSE&fields=period.fiscal-year.sort(DESC),entity.name.sort(ASC),concept.local-name.sort(ASC),fact.value,unit,fact.decimals,report.filing-date,report.sic-code,entity.cik,fact.offset(1000)\n"
     ]
    }
   ],
   "source": [
    "# This consolidates the fields defined above, and pulls API data via a loop:\n",
    "\n",
    "search_endpoint = 'https://api.xbrl.us/api/v1/fact/search' #looking for facts (Not reports, filers, etc.)\n",
    "orig_fields = params['fields']\n",
    "\n",
    "\n",
    "# Begin Loop ----------------------\n",
    "count = 0\n",
    "query_start = datetime.now()\n",
    "printed = False\n",
    "while True:\n",
    "    if not printed:\n",
    "        print(\"On\", query_start.strftime(\"%c\"), email, \"(client ID:\", str(client_id.split('-')[0]), \"...) started the query and\")  #client id defined in api connect cell\n",
    "        printed = True\n",
    "    res = requests.get(search_endpoint, params=params, headers={'Authorization' : 'Bearer {}'.format(access_token)}) # first GET request\n",
    "    res_json = res.json()\n",
    "    if 'error' in res_json:\n",
    "        print('There was an error: {}'.format(res_json['error_description']))\n",
    "        break\n",
    "\n",
    "    print(\"up to\", str(offset_value + res_json['paging']['limit']), \"records are found so far ...\")\n",
    "\n",
    "    res_df += res_json['data']\n",
    "\n",
    "    if res_json['paging']['count'] < res_json['paging']['limit']: #here it's checking for whether there's more to page & printing an update\n",
    "        print(\" - this set contained fewer than the\", res_json['paging']['limit'], \"possible, only\", str(res_json['paging']['count']), \"records.\")\n",
    "        break \n",
    "    else:\n",
    "        offset_value += res_json['paging']['limit'] # increments offset_value\n",
    "        if 100 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 10 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        elif 500 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 4 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "\n",
    "if not 'error' in res_json:\n",
    "    current_datetime = datetime.now().replace(microsecond=0)\n",
    "    time_taken = current_datetime - query_start\n",
    "    index = pd.DataFrame(res_df).index\n",
    "    total_rows = len(index)\n",
    "    your_limit = res_json['paging']['limit']\n",
    "    limit_message = \"If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\\n\"\n",
    "\n",
    "    if your_limit == 100:\n",
    "        print(\"\\nThis non-Member account has a limit of \" , 10 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "    elif your_limit == 500:\n",
    "        print(\"\\nThis Basic Individual Member account has a limit of \", 4 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "\n",
    "    print(\"\\nAt \" + current_datetime.strftime(\"%c\") +  \", the query finished with  \", str(total_rows), \"  rows returned in \" + str(time_taken) + \" for \\n\" +  urllib.parse.unquote(res.url))\n",
    "\n",
    "\n",
    "# OFF -- Dataframe creation -- (turns res_df, a list of dictionaries returned from API, and presents as a dataframe)\n",
    "\n",
    "#    df = pd.DataFrame(res_df)\n",
    "#    # the format truncates the HTML display of numerical values to two decimals; .csv data is unaffected\n",
    "#    pd.options.display.float_format = '{:,.2f}'.format\n",
    "#    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notable that for 250 companies, it only returned 213 rows in this first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining my 'Factory function'\n",
    "- Creating a wireframe of the dictionary I eventually want to insert into pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despite running my API query in batches, this only has to be done once\n",
    "- Creating frame based on all 503 SPY companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold all my companies\n",
    "all_company_financials_list_empty = []\n",
    "\n",
    "\n",
    "for company in SP500_CIK_List:\n",
    "    # STEP 1: create a label-list for yearxdata \n",
    "    temp_lineitem_list = []\n",
    "    for year in years: #1 year\n",
    "        for item in GAAP_Elements: #4 elements\n",
    "            temp_lineitem_list.append(f'FY{year}_{item}') # adds year_x_data term to lineitem list\n",
    "        # STEP 2: turn company yearxdata fields into a blank dictionary that holds None / NAs\n",
    "        company_dictionary = {x:None for x in temp_lineitem_list}\n",
    "    # STEP 3: Add Company Name and Append completed dictionary to master list\n",
    "    company_dictionary['CIK_number'] = str(company) #append a unique identifier to the dictionary    \n",
    "    all_company_financials_list_empty.append(company_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Blank Factory Dict (for time 1/2)\n",
    "- Lookup / Select Factory on CIK code\n",
    "- Update finanicals where there is a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create 'searcher' for loop to get index of dict with matching CIK code\n",
    "for dictionary in res_df: # loops same number of times as I have json dicts\n",
    "    for financial_dict in all_company_financials_list_empty: # now we iterate through each dictionary we have\n",
    "        if financial_dict['CIK_number'] == dictionary['entity.cik']:\n",
    "            \n",
    "            # update corresponding dictionary\n",
    "            \n",
    "            # first create temp variables\n",
    "            temp_yr = dictionary['period.fiscal-year']\n",
    "            temp_lclname = dictionary['concept.local-name']\n",
    "            \n",
    "            # then update matching line items\n",
    "            if f'FY{temp_yr}_{temp_lclname}' in financial_dict: # searches current financial_dict for matching financial line item\n",
    "                financial_dict[f'FY{temp_yr}_{temp_lclname}'] = dictionary['fact.value']\n",
    "                \n",
    "            else: \n",
    "                missing_vals.append(f'FY{temp_yr}_{temp_lclname}') # TO UPDATE: create and keep a list of missing values\n",
    "            #Before exiting loop, add additional data from json dict\n",
    "                ## Note: this code is inefficient -- will reassign the entity name, sic-code, filing each time a\n",
    "                ## this loop is entered (when SP500's CIK list finds a match in API's entity CIK)\n",
    "            # list of keys I want to append onto my custom dictionary\n",
    "            extra_info = ['entity.name','report.sic-code','report.filing-date']\n",
    "\n",
    "            for info in extra_info:\n",
    "                financial_dict[info] = dictionary[info] # Adds extra api metadata that will useful for my analysis\n",
    "        else: pass\n",
    "\n",
    "\n",
    "# first dict will have CIK code -- use that to ID the dictionary needed\n",
    "\n",
    "# Then go into lower loop to correclty slot datapoint into dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Pull 2/2 - SPY2\n",
    "Updating line 34 of the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset_value = 0\n",
    "res_df = []\n",
    "\n",
    "sic_code = [2080] ### v1 - OFF in API Call below\n",
    "\n",
    "periods = ['Y']\n",
    "\n",
    "years = [2022]  #,   # v1 - only doing 2022 and 202 while constructing... likely will variable-ize this \n",
    "         #2021,\n",
    "         #2020]   # , <- put comma back\n",
    "         #2019,   \n",
    "         #2018,\n",
    "         #2017\n",
    "        # put bracket back!\n",
    "\n",
    "string_sic = [str(int) for int in sic_code] # OFF in API URI\n",
    "string_years = [str(int) for int in years]\n",
    "\n",
    "fields = [ # this is the list of the characteristics of the data being returned by the query [COLUMNS]\n",
    "         'period.fiscal-year.sort(DESC)',\n",
    "         'entity.name.sort(ASC)',\n",
    "         'concept.local-name.sort(ASC)', # MARK - going to try and modify this from 'local-name' TO 'is-base'\n",
    "         'fact.value',\n",
    "         'unit',\n",
    "         'fact.decimals',\n",
    "         'report.filing-date',\n",
    "         'report.sic-code',             # [OFF in API URI] - \n",
    "         'entity.cik' \n",
    "        ]\n",
    "\n",
    "params = { \n",
    "         'concept.local-name': ','.join(GAAP_Elements),                  # MARK - modified this to use my specified list of FStmt Items\n",
    "         #'report.sic-code': ','.join(string_sic),                       # OFF -- spy companies\n",
    "         'entity.cik': ','.join(SPY2),                         # ON -- set to list of SP500\n",
    "         'period.fiscal-year': ','.join(string_years),                   # ON -- Set to 2022 only | MARK - turn on to limit the num of yrs (currently will provide all available)\n",
    "         'period.fiscal-period': ','.join(periods),\n",
    "         'fact.ultimus': 'TRUE', # return only the latest occurrence of a specific fact (eg. 2018 revenues)\n",
    "         'fact.has-dimensions': 'FALSE', # generally, 'FALSE' will return face financial data only\n",
    "         'fields': ','.join(fields)\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed Nov  8 01:11:50 2023 markstansky@gmail.com (client ID: 6a5b399f ...) started the query and\n",
      "up to 500 records are found so far ...\n",
      "up to 1000 records are found so far ...\n",
      "up to 1500 records are found so far ...\n",
      " - this set contained fewer than the 500 possible, only 279 records.\n",
      "\n",
      "This Basic Individual Member account has a limit of  2000  rows per query from our Public Filings Database. If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\n",
      "\n",
      "\n",
      "At Wed Nov  8 01:12:23 2023, the query finished with   1279   rows returned in 0:00:32.132243 for \n",
      "https://api.xbrl.us/api/v1/fact/search?concept.local-name=Revenues,NetCashProvidedByUsedInOperatingActivities,Assets,Liabilities&entity.cik=0001110803,0000879169,0001699150,0001145197,0000050863,0001571949,0000051253,0000051434,0000051644,0000896878,0001035267,0000914208,0001687229,0001478242,0001020569,0000728535,0000779152,0000052988,0000200406,0000833444,0000019617,0001043604,0000055067,0001944048,0001418135,0000091576,0001601046,0000055785,0000879101,0001506307,0000319201,0001637459,0000056873,0000202058,0000920148,0000707549,0001679273,0001300514,0001336920,0000920760,0001707925,0001335258,0001065696,0000936468,0000060086,0000060667,0001397187,0001489393,0000036270,0000101778,0001510295,0001278021,0001048286,0000062709,0000916076,0000062996,0001141391,0000891103,0000063754,0000063908,0000927653,0001613103,0000310158,0001326801,0001099219,0001037646,0000789570,0000827054,0000723125,0000789019,0000912595,0001682852,0000851968,0001179929,0000024545,0001103982,0001280452,0000865752,0001059556,0000895421,0001285785,0000068505,0001408198,0001120193,0001002047,0001065280,0001164727,0001564708,0001564708,0000753308,0000320187,0001111711,0000072331,0000702165,0000073124,0001133421,0001513761,0001013871,0000073309,0001045810,0000906163,0001413447,0000898173,0000797468,0000878927,0000029989,0001097864,0001039684,0001341439,0001781335,0000075362,0000075677,0001327567,0000813828,0000076334,0000723531,0001590955,0001633917,0000077360,0000077476,0000078003,0001004980,0001413329,0001534701,0000764622,0001038357,0000713676,0000945841,0000079879,0000922224,0001126328,0000080424,0000080661,0001045609,0001137774,0000788784,0000857005,0001393311,0000822416,0001604778,0001050915,0000804328,0001022079,0001037038,0000720005,0000101829,0000726728,0000910606,0000872589,0001281761,0001060391,0000943819,0000031791,0000315213,0001024478,0000084839,0000882835,0000745732,0000884887,0000064040,0001108524,0001034054,0000087347,0001137789,0001012100,0001032208,0001373715,0000089800,0001063761,0000004127,0000091419,0000091440,0001419612,0000092122,0000092380,0000093556,0000829224,0000093751,0001022671,0001757898,0000310764,0001601712,0000883241,0000096021,0001283699,0001113169,0000946581,0001116132,0001389170,0000027419,0001385157,0001094285,0000096943,0000097210,0001318605,0000097476,0000217346,0000097745,0000109198,0000916365,0001466258,0001260221,0000086312,0000864749,0000092230,0000860731,0000100493,0000036104,0000074208,0001403568,0000100885,0000100517,0001090727,0001067701,0000731766,0000352915,0001035002,0000740260,0001967680,0001014473,0001442145,0000732712,0000875320,0000103379,0001792044,0001705696,0001403161,0001396009,0000943452,0001618921,0000104169,0001437107,0000823768,0001000697,0000783325,0000072971,0000766704,0000105770,0000106040,0001732845,0000106535,0000106640,0000107263,0001140536,0000277135,0001174922,0000072903,0001524472,0001041061,0000877212,0001136869,0000109380,0001555280&period.fiscal-year=2022&period.fiscal-period=Y&fact.ultimus=TRUE&fact.has-dimensions=FALSE&fields=period.fiscal-year.sort(DESC),entity.name.sort(ASC),concept.local-name.sort(ASC),fact.value,unit,fact.decimals,report.filing-date,report.sic-code,entity.cik,fact.offset(1000)\n"
     ]
    }
   ],
   "source": [
    "# This consolidates the fields defined above, and pulls API data via a loop:\n",
    "\n",
    "search_endpoint = 'https://api.xbrl.us/api/v1/fact/search' #looking for facts (Not reports, filers, etc.)\n",
    "orig_fields = params['fields']\n",
    "\n",
    "\n",
    "# Begin Loop ----------------------\n",
    "count = 0\n",
    "query_start = datetime.now()\n",
    "printed = False\n",
    "while True:\n",
    "    if not printed:\n",
    "        print(\"On\", query_start.strftime(\"%c\"), email, \"(client ID:\", str(client_id.split('-')[0]), \"...) started the query and\")  #client id defined in api connect cell\n",
    "        printed = True\n",
    "    res = requests.get(search_endpoint, params=params, headers={'Authorization' : 'Bearer {}'.format(access_token)}) # first GET request\n",
    "    res_json = res.json()\n",
    "    if 'error' in res_json:\n",
    "        print('There was an error: {}'.format(res_json['error_description']))\n",
    "        break\n",
    "\n",
    "    print(\"up to\", str(offset_value + res_json['paging']['limit']), \"records are found so far ...\")\n",
    "\n",
    "    res_df += res_json['data']\n",
    "\n",
    "    if res_json['paging']['count'] < res_json['paging']['limit']: #here it's checking for whether there's more to page & printing an update\n",
    "        print(\" - this set contained fewer than the\", res_json['paging']['limit'], \"possible, only\", str(res_json['paging']['count']), \"records.\")\n",
    "        break \n",
    "    else:\n",
    "        offset_value += res_json['paging']['limit'] # increments offset_value\n",
    "        if 100 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 10 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        elif 500 == res_json['paging']['limit']:\n",
    "                params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "                if offset_value == 4 * res_json['paging']['limit']:\n",
    "                        break\n",
    "        params['fields'] = orig_fields + ',fact.offset({})'.format(offset_value)\n",
    "\n",
    "if not 'error' in res_json:\n",
    "    current_datetime = datetime.now().replace(microsecond=0)\n",
    "    time_taken = current_datetime - query_start\n",
    "    index = pd.DataFrame(res_df).index\n",
    "    total_rows = len(index)\n",
    "    your_limit = res_json['paging']['limit']\n",
    "    limit_message = \"If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\\n\"\n",
    "\n",
    "    if your_limit == 100:\n",
    "        print(\"\\nThis non-Member account has a limit of \" , 10 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "    elif your_limit == 500:\n",
    "        print(\"\\nThis Basic Individual Member account has a limit of \", 4 * your_limit, \" rows per query from our Public Filings Database. \" + limit_message)\n",
    "\n",
    "    print(\"\\nAt \" + current_datetime.strftime(\"%c\") +  \", the query finished with  \", str(total_rows), \"  rows returned in \" + str(time_taken) + \" for \\n\" +  urllib.parse.unquote(res.url))\n",
    "\n",
    "\n",
    "# OFF -- Dataframe creation -- (turns res_df, a list of dictionaries returned from API, and presents as a dataframe)\n",
    "\n",
    "#    df = pd.DataFrame(res_df)\n",
    "#    # the format truncates the HTML display of numerical values to two decimals; .csv data is unaffected\n",
    "#    pd.options.display.float_format = '{:,.2f}'.format\n",
    "#    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the 50% filled Factory Dict (for time 2/2)\n",
    "- Just need to run this code block a second time to find and place the remaining values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create 'searcher' for loop to get index of dict with matching CIK code\n",
    "for dictionary in res_df: # loops same number of times as I have json dicts\n",
    "    for financial_dict in all_company_financials_list_empty: # now we iterate through each dictionary we have\n",
    "        if financial_dict['CIK_number'] == dictionary['entity.cik']:\n",
    "            \n",
    "            # update corresponding dictionary\n",
    "            \n",
    "            # first create temp variables\n",
    "            temp_yr = dictionary['period.fiscal-year']\n",
    "            temp_lclname = dictionary['concept.local-name']\n",
    "            \n",
    "            # then update matching line items\n",
    "            if f'FY{temp_yr}_{temp_lclname}' in financial_dict: # searches current financial_dict for matching financial line item\n",
    "                financial_dict[f'FY{temp_yr}_{temp_lclname}'] = dictionary['fact.value']\n",
    "                \n",
    "            else: \n",
    "                missing_vals.append(f'FY{temp_yr}_{temp_lclname}') # TO UPDATE: create and keep a list of missing values\n",
    "            #Before exiting loop, add additional data from json dict\n",
    "                ## Note: this code is inefficient -- will reassign the entity name, sic-code, filing each time a\n",
    "                ## this loop is entered (when SP500's CIK list finds a match in API's entity CIK)\n",
    "            # list of keys I want to append onto my custom dictionary\n",
    "            extra_info = ['entity.name','report.sic-code','report.filing-date']\n",
    "\n",
    "            for info in extra_info:\n",
    "                financial_dict[info] = dictionary[info] # Adds extra api metadata that will useful for my analysis\n",
    "        else: pass\n",
    "\n",
    "\n",
    "# first dict will have CIK code -- use that to ID the dictionary needed\n",
    "\n",
    "# Then go into lower loop to correclty slot datapoint into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FY2022_Revenues</th>\n",
       "      <th>FY2022_NetCashProvidedByUsedInOperatingActivities</th>\n",
       "      <th>FY2022_Assets</th>\n",
       "      <th>FY2022_Liabilities</th>\n",
       "      <th>CIK_number</th>\n",
       "      <th>entity.name</th>\n",
       "      <th>report.sic-code</th>\n",
       "      <th>report.filing-date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.422900e+10</td>\n",
       "      <td>5.591000e+09</td>\n",
       "      <td>46455000000</td>\n",
       "      <td>3.168500e+10</td>\n",
       "      <td>0000066740</td>\n",
       "      <td>3M COMPANY</td>\n",
       "      <td>3841</td>\n",
       "      <td>2023-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.914000e+08</td>\n",
       "      <td>3332300000</td>\n",
       "      <td>1.584600e+09</td>\n",
       "      <td>0000091142</td>\n",
       "      <td>A. O. Smith Corporation</td>\n",
       "      <td>3630</td>\n",
       "      <td>2023-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.365300e+10</td>\n",
       "      <td>9.581000e+09</td>\n",
       "      <td>74438000000</td>\n",
       "      <td>3.001100e+10</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>2834</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.805400e+10</td>\n",
       "      <td>2.494300e+10</td>\n",
       "      <td>138805000000</td>\n",
       "      <td>1.215180e+11</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>2834</td>\n",
       "      <td>2023-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.159430e+10</td>\n",
       "      <td>9.541129e+09</td>\n",
       "      <td>47263390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001467373</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>7389</td>\n",
       "      <td>2023-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>6.842000e+09</td>\n",
       "      <td>1.427000e+09</td>\n",
       "      <td>5846000000</td>\n",
       "      <td>1.472200e+10</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>YUM! BRANDS, INC.</td>\n",
       "      <td>5812</td>\n",
       "      <td>2023-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5.781000e+09</td>\n",
       "      <td>4.880000e+08</td>\n",
       "      <td>7529000000</td>\n",
       "      <td>4.796000e+09</td>\n",
       "      <td>0000877212</td>\n",
       "      <td>Zebra Technologies Corporation</td>\n",
       "      <td>3560</td>\n",
       "      <td>2023-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21066000000</td>\n",
       "      <td>9.039000e+09</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>ZIMMER BIOMET HOLDINGS, INC.</td>\n",
       "      <td>3842</td>\n",
       "      <td>2023-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.140000e+08</td>\n",
       "      <td>1.470000e+09</td>\n",
       "      <td>89545000000</td>\n",
       "      <td>8.465200e+10</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>ZIONS BANCORPORATION, NATIONAL ASSOCIATION</td>\n",
       "      <td>6021</td>\n",
       "      <td>2023-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>8.080000e+09</td>\n",
       "      <td>1.912000e+09</td>\n",
       "      <td>14925000000</td>\n",
       "      <td>1.052200e+10</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>2834</td>\n",
       "      <td>2023-02-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FY2022_Revenues  FY2022_NetCashProvidedByUsedInOperatingActivities  \\\n",
       "0       3.422900e+10                                       5.591000e+09   \n",
       "1                NaN                                       3.914000e+08   \n",
       "2       4.365300e+10                                       9.581000e+09   \n",
       "3       5.805400e+10                                       2.494300e+10   \n",
       "4       6.159430e+10                                       9.541129e+09   \n",
       "..               ...                                                ...   \n",
       "498     6.842000e+09                                       1.427000e+09   \n",
       "499     5.781000e+09                                       4.880000e+08   \n",
       "500              NaN                                                NaN   \n",
       "501     6.140000e+08                                       1.470000e+09   \n",
       "502     8.080000e+09                                       1.912000e+09   \n",
       "\n",
       "     FY2022_Assets  FY2022_Liabilities  CIK_number  \\\n",
       "0      46455000000        3.168500e+10  0000066740   \n",
       "1       3332300000        1.584600e+09  0000091142   \n",
       "2      74438000000        3.001100e+10  0000001800   \n",
       "3     138805000000        1.215180e+11  0001551152   \n",
       "4      47263390000                 NaN  0001467373   \n",
       "..             ...                 ...         ...   \n",
       "498     5846000000        1.472200e+10  0001041061   \n",
       "499     7529000000        4.796000e+09  0000877212   \n",
       "500    21066000000        9.039000e+09  0001136869   \n",
       "501    89545000000        8.465200e+10  0000109380   \n",
       "502    14925000000        1.052200e+10  0001555280   \n",
       "\n",
       "                                    entity.name  report.sic-code  \\\n",
       "0                                    3M COMPANY             3841   \n",
       "1                       A. O. Smith Corporation             3630   \n",
       "2                           ABBOTT LABORATORIES             2834   \n",
       "3                                   AbbVie Inc.             2834   \n",
       "4                                 Accenture plc             7389   \n",
       "..                                          ...              ...   \n",
       "498                           YUM! BRANDS, INC.             5812   \n",
       "499              Zebra Technologies Corporation             3560   \n",
       "500                ZIMMER BIOMET HOLDINGS, INC.             3842   \n",
       "501  ZIONS BANCORPORATION, NATIONAL ASSOCIATION             6021   \n",
       "502                                 Zoetis Inc.             2834   \n",
       "\n",
       "    report.filing-date  \n",
       "0           2023-02-08  \n",
       "1           2023-02-14  \n",
       "2           2023-11-01  \n",
       "3           2023-02-17  \n",
       "4           2023-10-12  \n",
       "..                 ...  \n",
       "498         2023-02-27  \n",
       "499         2023-02-16  \n",
       "500         2023-05-02  \n",
       "501         2023-02-23  \n",
       "502         2023-02-14  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_df = pd.DataFrame(all_company_financials_list_empty) \n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETS GOOOOOOOOOO\n",
    "\n",
    "- Going to explore it quickly then will export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   FY2022_Revenues                                    324 non-null    float64\n",
      " 1   FY2022_NetCashProvidedByUsedInOperatingActivities  487 non-null    float64\n",
      " 2   FY2022_Assets                                      503 non-null    int64  \n",
      " 3   FY2022_Liabilities                                 472 non-null    float64\n",
      " 4   CIK_number                                         503 non-null    object \n",
      " 5   entity.name                                        503 non-null    object \n",
      " 6   report.sic-code                                    503 non-null    int64  \n",
      " 7   report.filing-date                                 503 non-null    object \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 31.6+ KB\n"
     ]
    }
   ],
   "source": [
    "SP500_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it interesting that I have full data in 5/8 columns.  The columns where I don't include Revenue, Cash From Ops, and Liabilities.\n",
    "\n",
    "\n",
    "I had trouble with several Revenue cases as I was builing the API, it had to do with the type of company and how they labeled revenue.  I will need to address this in Sprint 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Cleaning so only the complete rows come to the next step in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Chapter', 'SICDivision', 'SICIndustryGroup','SICMajGroup','SICPrimary','Voluntary','YearFiled','Date10k1Before',\n",
    " 'Sales1Before','Sales1Before','EbitBefore','Assets1Before','Liab1Before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_ordered = ['CIK_number','entity.name','report.sic-code','report.filing-date','FY2022_Revenues',\n",
    "               'FY2022_NetCashProvidedByUsedInOperatingActivities','FY2022_Assets','FY2022_Liabilities']\n",
    "               \n",
    "SP500_df_ordered = SP500_df[spy_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK_number</th>\n",
       "      <th>entity.name</th>\n",
       "      <th>report.sic-code</th>\n",
       "      <th>report.filing-date</th>\n",
       "      <th>FY2022_Revenues</th>\n",
       "      <th>FY2022_NetCashProvidedByUsedInOperatingActivities</th>\n",
       "      <th>FY2022_Assets</th>\n",
       "      <th>FY2022_Liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000066740</td>\n",
       "      <td>3M COMPANY</td>\n",
       "      <td>3841</td>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>3.422900e+10</td>\n",
       "      <td>5.591000e+09</td>\n",
       "      <td>46455000000</td>\n",
       "      <td>3.168500e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000091142</td>\n",
       "      <td>A. O. Smith Corporation</td>\n",
       "      <td>3630</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.914000e+08</td>\n",
       "      <td>3332300000</td>\n",
       "      <td>1.584600e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000001800</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>2834</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>4.365300e+10</td>\n",
       "      <td>9.581000e+09</td>\n",
       "      <td>74438000000</td>\n",
       "      <td>3.001100e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001551152</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>2834</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>5.805400e+10</td>\n",
       "      <td>2.494300e+10</td>\n",
       "      <td>138805000000</td>\n",
       "      <td>1.215180e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001467373</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>7389</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>6.159430e+10</td>\n",
       "      <td>9.541129e+09</td>\n",
       "      <td>47263390000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIK_number              entity.name  report.sic-code report.filing-date  \\\n",
       "0  0000066740               3M COMPANY             3841         2023-02-08   \n",
       "1  0000091142  A. O. Smith Corporation             3630         2023-02-14   \n",
       "2  0000001800      ABBOTT LABORATORIES             2834         2023-11-01   \n",
       "3  0001551152              AbbVie Inc.             2834         2023-02-17   \n",
       "4  0001467373            Accenture plc             7389         2023-10-12   \n",
       "\n",
       "   FY2022_Revenues  FY2022_NetCashProvidedByUsedInOperatingActivities  \\\n",
       "0     3.422900e+10                                       5.591000e+09   \n",
       "1              NaN                                       3.914000e+08   \n",
       "2     4.365300e+10                                       9.581000e+09   \n",
       "3     5.805400e+10                                       2.494300e+10   \n",
       "4     6.159430e+10                                       9.541129e+09   \n",
       "\n",
       "   FY2022_Assets  FY2022_Liabilities  \n",
       "0    46455000000        3.168500e+10  \n",
       "1     3332300000        1.584600e+09  \n",
       "2    74438000000        3.001100e+10  \n",
       "3   138805000000        1.215180e+11  \n",
       "4    47263390000                 NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_df_ordered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out nulls in the financials\n",
    "fin_cols=['FY2022_Revenues','FY2022_NetCashProvidedByUsedInOperatingActivities','FY2022_Assets','FY2022_Liabilities']\n",
    "SP500_df_export = SP500_df_ordered[SP500_df_ordered[fin_cols].notnull().all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 303 columns are less than what I wanted but I will address those non-revenue cases in Sprint 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To CSV\n",
    "SP500_df_export.to_csv('/Users/markstansky/Desktop/Brainstation/Capstone/Sprint_2/Submission/sp500_api_financials_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
